server {
  listen 8282;

  server_name lastlog;

  default_type application/json;

  location /lastlog/json {
    content_by_lua_block {
      local lastlog = require "lastlog"
      local cjson = require "cjson"
      local req_stat,
            ups_stat,
            http_x,
            start_time, end_time,
            start_request_time, end_request_time = lastlog.get_statistic(ngx.var.arg_period, ngx.var.arg_backward)
      ngx.say(cjson.encode({ requests_statistic = req_stat, upstream_staistic = ups_stat, http_x = http_x }))
    }
  }

  location /lastlog/text {
    default_type text/plain;
    content_by_lua_block {
      local lastlog = require "lastlog"
      local cjson = require "cjson"

      local req_stat,
            ups_stat,
            http_x,
            start_time, end_time,
            start_request_time, end_request_time = lastlog.get_statistic(ngx.var.arg_period, ngx.var.arg_backward)

      ngx.say("Upstreams")
      ngx.say()

      local round = function(num, idp)
        local mult = 10^(idp or 0)
        return math.floor(num * mult + 0.5) / mult
      end

      for u, peers in pairs(ups_stat.upstreams)
      do
        ngx.say("    " .. u)

        for peer, data in pairs(peers)
        do
          ngx.say("        server " .. peer)
          for status, stat in pairs(data)
          do
            ngx.say("            http_" .. status .. " : count=" .. stat.count ..
                                                    ", average latency=" .. round(1000 * stat.latency, 1) .. "ms" ..
                                                    ", average rps=" .. math.floor(stat.count / (end_time - start_time)) ..
                                                    ", current rps=" .. math.floor(stat.current_rps or 0))
          end
          ngx.say()
        end

        ngx.say("        Average latency: " .. round(1000 * ups_stat.stat[u].average_latency, 1) .. "ms")
        ngx.say("        Average req/seq: " .. math.floor(ups_stat.stat[u].average_rps))
        ngx.say("        Current req/seq: " .. math.floor(ups_stat.stat[u].current_rps))
        ngx.say()
      end

      ngx.say("Requests")
      ngx.say()
      ngx.say("  Latency(ms) |    Count |  avg RPS | curr RPS | Request")
      for status, peers in pairs(http_x)
      do
        ngx.say("    http_" .. status)

        local sum_latency = 0
        local peers_count = 0

        for _, data in ipairs(peers)
        do
          ngx.say(string.format("        %5.1f : %8d : %8d : %8d : %s", 1000 * data.stat.latency,
                                                                        data.stat.count,
                                                                        math.floor(data.stat.count / (end_time - start_time)),
                                                                        data.stat.current_rps or 0,
                                                                        data.uri))
          sum_latency = sum_latency + data.stat.latency
          peers_count = peers_count + 1
        end

        ngx.say()
        ngx.say("        Average latency: " .. round(1000 * sum_latency / peers_count, 1) .. "ms")
        ngx.say()
      end

      ngx.say("Average latency: " .. round(1000 * req_stat.stat.average_latency, 1) .. "ms")
      ngx.say("Average req/seq: " .. math.floor(req_stat.stat.average_rps))
      ngx.say("Current req/seq: " .. math.floor(req_stat.stat.current_rps))
    }
  }
}